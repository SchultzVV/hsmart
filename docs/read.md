Plano de Execu√ß√£o (3 Dias)

#### Dia 1: Configura√ß√£o do Ambiente e Estrutura√ß√£o
*   Configurar o ambiente Docker e criar um docker-compose.yaml b√°sico.
*   Escolher e configurar um Vector Database open-source (exemplo: FAISS, ChromaDB, Weaviate).
*   Criar a estrutura dos microsservi√ßos:
*   Service 1: API para processar documentos e armazenar embeddings no Vector DB.
*   Service 2: API para receber perguntas, recuperar contexto e gerar respostas via LLM.
#### Dia 2: Implementa√ß√£o das APIs
*   Implementar a API de ingest√£o de documentos:
*   Extrair texto da p√°gina fornecida.
*   Gerar embeddings do texto com Sentence Transformers ou OpenAI embeddings.
*   Armazenar embeddings no Vector Database.
*   Implementar a API de consulta:
*   Receber perguntas.
*   Buscar os trechos mais relevantes no Vector DB.
*   Passar o contexto para um modelo LLM (ex: Llama, GPT, Mistral).
*   Retornar a resposta gerada.
#### Dia 3: Testes e Documenta√ß√£o
*   Criar scripts de teste para cURL/Postman.
*   Testar os microsservi√ßos juntos.
*   Criar o README.md com instru√ß√µes de execu√ß√£o.
*   Subir o c√≥digo para o GitHub e validar a execu√ß√£o com docker-compose up.
*   Se precisar de ajuda com alguma parte espec√≠fica, posso te guiar na implementa√ß√£o! üöÄ

echo "TOKEN_GITHUB" | docker login ghcr.io -u SEU_USUARIO --password-stdin
