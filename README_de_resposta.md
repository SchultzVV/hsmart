## RESPOSTA 
Ap√≥s construir os servi√ßos de ingest√£o e resposta, podemos obter o resultado pedido no PDF com o endpoint:

##### Usando o Retrivial_service
```bash
curl -X POST "http://127.0.0.1:5004/query" \
     -H "Content-Type: application/json" \
     -d '{"question": "O que √© a Hotmart?"}'
```
Deve receber uma resposta JSON:
```json
{
  "response": ": A Hotmart \u00e9 um ecossistema completo em constante evolucion\u00e1ria para trazer ainda mais solu\u00e7es para criar e escalar neg\u00f3cios digital. Dados mostram que, na Hotmart, creators faturam 35% mais, sem mexer no esfor\u00e7o operacional. Isso gra\u00e7as ao rapid carregamento, alta taxa de aprova\u00e7o, variedade de formas de pagamento, usabilidade agrad\u00e1vel e ferramentas especficas para aumentar as vendas, como o Order Bump & Funil de Vendas, por exemplo."
}
```
A resposta ajustada √© 
```text
Resposta:
A Hotmart √© um ecossistema completo em constante evolucion√°ria para trazer ainda mais solu√ßes para criar e escalar neg√≥cios digital. Dados mostram que, na Hotmart, creators faturam 35% mais, sem mexer no esfor√ßo operacional. Isso gra√ßas ao rapid carregamento, alta taxa de aprova√ßo, variedade de formas de pagamento, usabilidade agrad√°vel e ferramentas especficas para aumentar as vendas, como o Order Bump & Funil de Vendas, por exemplo.
```
A resposta tamb√©m √© salva num arquivo [`ultima_resposta.txt`](services/retrieval_service/ultima_resposta.txt)


##### Ingestion_service  
A imagem de ingest√£o de informa√ß√µes no banco de vetores qdrant faz automaticamente a coleta, ingest√£o e incorpora√ß√£o das informa√ß√µes. O endpoint de ingest√£o pode ser usado assim: 

```bash
curl -X POST "http://127.0.0.1:5003/ingest" \
     -H "Content-Type: application/json" \
     -d '{"text": "A Hotmart √© uma plataforma para criadores de conte√∫do venderem seus produtos digitais."}'
```
Deve receber uma resposta JSON:
```json
{"message": "Texto armazenado com sucesso"}
```


### Considera√ß√µes

Durante a implementa√ß√£o do `retrieval_service`, optei por n√£o utilizar a GPU e executei os modelos exclusivamente na CPU. A decis√£o foi baseada na configura√ß√£o da m√°quina utilizada, que possui uma CPU com 16GB de RAM e uma GPU mais antiga, o que poderia comprometer a estabilidade e compatibilidade do processamento. Para garantir melhor desempenho na infer√™ncia do modelo, selecionei o google/flan-t5-small, uma op√ß√£o otimizada para execu√ß√£o em CPU.

Podemos considerar o teste das melhorias futuras.

#### üìú Poss√≠veis Melhorias Futuras

Embora o sistema esteja funcional e operacional, h√° algumas otimiza√ß√µes que podem aprimorar a precis√£o das respostas e a efici√™ncia do modelo:

##### **1Ô∏è‚É£ Melhoria na Gera√ß√£o das Respostas**
- Testar modelos mais robustos, como **`google/flan-t5-base`** ou **`tiiuae/falcon-7b-instruct`**, caso haja mais recursos computacionais dispon√≠veis.

- Refinar o **p√≥s-processamento das respostas**, eliminando padr√µes degenerativos e garantindo maior fluidez na linguagem.

##### **2Ô∏è‚É£ Otimiza√ß√£o da Recupera√ß√£o de Contexto**
- Ajustar a **quantidade de trechos retornados do Qdrant** para fornecer mais informa√ß√µes ao modelo na hora de gerar respostas.

- Implementar **re-ranking dos resultados**, priorizando os trechos mais relevantes para cada pergunta.

- Testar o uso de embeddings mais avan√ßados para melhorar a qualidade da busca sem√¢ntica.

##### **4Ô∏è‚É£ Expans√£o da Base de Conhecimento**
- Criar um endpoint para **ingest√£o cont√≠nua de novos documentos**, permitindo a atualiza√ß√£o da base de conhecimento sem necessidade de reinicializa√ß√£o.

- Habilitar um **mecanismo de feedback**, onde os usu√°rios possam avaliar as respostas geradas, permitindo que o sistema aprenda e melhore continuamente.

- Integrar uma API externa para complementar o conhecimento armazenado, garantindo que informa√ß√µes atualizadas possam ser incorporadas automaticamente.

Essas melhorias podem tornar o sistema mais inteligente, eficiente e adapt√°vel, garantindo respostas mais precisas e relevantes para diferentes tipos de perguntas.
